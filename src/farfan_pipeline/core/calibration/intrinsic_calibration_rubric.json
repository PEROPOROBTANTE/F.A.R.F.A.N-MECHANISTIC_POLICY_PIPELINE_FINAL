{
  "_metadata": {
    "version": "1.1.0",
    "description": "Machine-readable rubric for computing intrinsic calibration scores",
    "spec_reference": "CALIBRATION_CANONICAL_COHERENCE_ANALYSIS.md",
    "last_updated": "2025-12-03T16:54:00Z",
    "changelog": "v1.1.0: Aligned b_impl weights and field names with canonical specification"
  },
  "b_theory": {
    "description": "Theoretical foundation quality score",
    "weights": {
      "grounded_in_valid_statistics": 0.4,
      "logical_consistency": 0.3,
      "appropriate_assumptions": 0.3
    },
    "rules": {
      "grounded_in_valid_statistics": {
        "description": "Statistical grounding based on keywords and method semantics",
        "scoring": {
          "has_bayesian_or_statistical_model": {
            "keywords": [
              "bayesian",
              "statistical",
              "probability",
              "distribution",
              "regression",
              "coefficient"
            ],
            "threshold": 3,
            "score": 1.0
          },
          "has_some_statistical_grounding": {
            "keywords": [
              "bayesian",
              "statistical",
              "probability",
              "distribution",
              "regression",
              "coefficient"
            ],
            "threshold": 1,
            "score": 0.5
          },
          "no_statistical_grounding": {
            "score": 0.0
          }
        }
      },
      "logical_consistency": {
        "description": "Documentation quality and logical structure",
        "scoring": {
          "complete_documentation": {
            "conditions": [
              "has_docstring_gt_50_chars",
              "has_returns_doc",
              "has_params_doc"
            ],
            "score": 1.0
          },
          "partial_documentation": {
            "conditions": [
              "has_docstring_gt_20_chars"
            ],
            "score": 0.5
          },
          "minimal_documentation": {
            "score": 0.2
          }
        }
      },
      "appropriate_assumptions": {
        "description": "Explicit assumption documentation",
        "scoring": {
          "assumptions_documented": {
            "keywords": [
              "assum",
              "constraint",
              "precondition",
              "requires"
            ],
            "score": 0.7
          },
          "implicit_assumptions": {
            "score": 0.4
          }
        }
      }
    }
  },
  "b_impl": {
    "description": "Implementation quality score - Canonical specification from CALIBRATION_CANONICAL_COHERENCE_ANALYSIS.md",
    "weights": {
      "test_coverage": 0.35,
      "type_annotations": 0.25,
      "error_handling": 0.25,
      "documentation": 0.15
    },
    "rules": {
      "test_coverage": {
        "description": "Evidence of actual tests running (≥ 80% → 1.0, linear below)",
        "scoring": {
          "has_test_evidence": {
            "description": "Test runs verified or high-quality test suite present",
            "score": 0.8
          },
          "has_test_files": {
            "description": "Test files exist but execution not verified",
            "score": 0.5
          },
          "no_test_evidence": {
            "description": "No test evidence found",
            "default": true,
            "score": 0.2
          }
        },
        "note": "Conservative scoring until CI/test metrics available"
      },
      "error_handling": {
        "description": "Error handling and robustness patterns (all paths covered → 1.0)",
        "scoring": {
          "comprehensive_handling": {
            "description": "Try/except blocks, input validation, defensive checks",
            "score": 0.8
          },
          "basic_handling": {
            "description": "Some error handling present",
            "score": 0.5
          },
          "minimal_handling": {
            "description": "Limited or no explicit error handling",
            "default": true,
            "score": 0.3
          }
        }
      },
      "type_annotations": {
        "description": "Type annotation coverage (complete → 1.0, partial weighted)",
        "scoring": {
          "complete_annotations": {
            "description": "Full type coverage on parameters and returns",
            "score": 1.0
          },
          "partial_annotations": {
            "description": "Some type annotations present",
            "formula": "(typed_params / total_params) * 0.7 + (0.3 if has_return_type else 0)",
            "score": "computed"
          },
          "no_annotations": {
            "description": "No type annotations",
            "default": true,
            "score": 0.0
          }
        },
        "note": "Type hints are DOCUMENTATION, not runtime enforcement. They score here, not in enforcement."
      },
      "documentation": {
        "description": "Documentation quality (complete API docs → 1.0)",
        "scoring": {
          "formula": "(0.4 if doc_length > 50 else 0.1) + (0.25 if has_params_doc else 0) + (0.25 if has_returns_doc else 0) + (0.1 if has_examples else 0)"
        },
        "note": "Comprehensive docstrings with parameters, returns, and examples"
      }
    }
  },
  "b_deploy": {
    "description": "Deployment maturity score",
    "weights": {
      "validation_runs": 0.4,
      "stability_coefficient": 0.35,
      "failure_rate": 0.25
    },
    "rules": {
      "layer_maturity_baseline": {
        "description": "Base maturity by layer classification",
        "scoring": {
          "orchestrator": 0.7,
          "processor": 0.6,
          "analyzer": 0.5,
          "ingestion": 0.6,
          "executor": 0.5,
          "utility": 0.6,
          "unknown": 0.3
        }
      },
      "validation_runs": {
        "description": "Validation run estimates scaled from layer maturity",
        "scoring": {
          "formula": "layer_maturity_baseline * 0.8"
        }
      },
      "stability_coefficient": {
        "description": "Stability estimates scaled from layer maturity",
        "scoring": {
          "formula": "layer_maturity_baseline * 0.9"
        }
      },
      "failure_rate": {
        "description": "Failure rate estimates scaled from layer maturity",
        "scoring": {
          "formula": "layer_maturity_baseline * 0.85"
        }
      }
    }
  },
  "exclusion_criteria": {
    "description": "Rules for excluding methods from calibration",
    "patterns": [
      {
        "pattern": "__init__",
        "reason": "Constructor - non-analytical"
      },
      {
        "pattern": "__str__",
        "reason": "String representation - non-analytical"
      },
      {
        "pattern": "__repr__",
        "reason": "String representation - non-analytical"
      },
      {
        "pattern": "__eq__",
        "reason": "Equality comparison - non-analytical"
      },
      {
        "pattern": "__hash__",
        "reason": "Hash function - non-analytical"
      },
      {
        "pattern": "__len__",
        "reason": "Length accessor - non-analytical"
      },
      {
        "pattern": "_format_",
        "reason": "Formatting utility - non-semantic"
      },
      {
        "pattern": "_log_",
        "reason": "Logging utility - non-semantic"
      },
      {
        "pattern": "_print_",
        "reason": "Print utility - non-semantic"
      },
      {
        "pattern": "to_string",
        "reason": "Serialization - non-semantic"
      },
      {
        "pattern": "to_json",
        "reason": "Serialization - non-semantic"
      },
      {
        "pattern": "to_dict",
        "reason": "Serialization - non-semantic"
      },
      {
        "pattern": "visit_",
        "reason": "AST visitor - non-analytical"
      }
    ],
    "additional_rules": {
      "private_utility_in_utility_layer": {
        "condition": "method_name.startswith('_') and layer == 'utility' and not analytically_active",
        "reason": "Private utility function - non-analytical"
      },
      "pure_getter": {
        "condition": "method_name.startswith('get_') and return_type in ['str', 'Path', 'bool'] and not analytically_active",
        "reason": "Simple getter with no analytical logic"
      }
    }
  },
  "calibration_triggers": {
    "description": "3-question decision automaton for determining calibration requirement",
    "questions": {
      "q1_analytically_active": {
        "question": "Can this method change what is true in the pipeline?",
        "indicators": {
          "analytical_verbs": [
            "score",
            "compute",
            "calculate",
            "evaluate",
            "assess",
            "validate",
            "filter",
            "select",
            "transform",
            "aggregate",
            "detect",
            "extract",
            "classify",
            "rank",
            "weight",
            "normalize",
            "calibrate",
            "adjust",
            "infer",
            "predict",
            "estimate",
            "measure",
            "analyze",
            "process"
          ],
          "check_method_name": true,
          "check_docstring": true
        }
      },
      "q2_parametric": {
        "question": "Does it encode assumptions or knobs that matter?",
        "indicators": {
          "parametric_keywords": [
            "threshold",
            "prior",
            "weight",
            "parameter",
            "coefficient",
            "model",
            "rule",
            "heuristic",
            "assumption",
            "criterion"
          ],
          "check_docstring": true,
          "check_layer": [
            "analyzer",
            "processor",
            "executor"
          ]
        }
      },
      "q3_safety_critical": {
        "question": "Would a bug/misuse materially mislead an evaluation?",
        "indicators": {
          "critical_layers": [
            "analyzer",
            "processor",
            "orchestrator"
          ],
          "evaluative_return_types": [
            "float",
            "int",
            "dict",
            "list"
          ],
          "exclude_simple_getters": true
        }
      }
    },
    "decision": "If ANY question returns YES and method is NOT explicitly excluded, then calibration is REQUIRED"
  }
}